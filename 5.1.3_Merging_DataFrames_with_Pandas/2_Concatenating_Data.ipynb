{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending pandas Series\n",
    "In this exercise, you'll load sales data from the months January, February, and March into DataFrames. Then, you'll extract Series with the **`'Units'`** column from each and append them together with method chaining using **`.append()`**.\n",
    "\n",
    "To check that the stacking worked, you'll print slices from these Series, and finally, you'll add the result to figure out the total units sold in the first quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 'sales-jan-2015.csv' into a DataFrame: jan\n",
    "jan = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Sales/sales-jan-2015.csv', \n",
    "                  parse_dates=True, index_col='Date')\n",
    "\n",
    "# Load 'sales-feb-2015.csv' into a DataFrame: feb\n",
    "feb = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Sales/sales-feb-2015.csv', \n",
    "                  parse_dates=True, index_col='Date')\n",
    "\n",
    "# Load 'sales-mar-2015.csv' into a DataFrame: mar\n",
    "mar = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Sales/sales-mar-2015.csv', \n",
    "                  parse_dates=True, index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Units' column from jan: jan_units\n",
    "jan_units = jan['Units']\n",
    "\n",
    "# Extract the 'Units' column from feb: feb_units\n",
    "feb_units = feb['Units']\n",
    "\n",
    "# Extract the 'Units' column from mar: mar_units\n",
    "mar_units = mar['Units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Append feb_units and then mar_units to jan_units: quarter1\n",
    "quarter1 = jan_units.append(feb_units).append(mar_units)\n",
    "\n",
    "# Print the first slice from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "\n",
    "# Print the second slice from quarter1\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7,2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute & print total sales in quarter1\n",
    "quarter1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating pandas Series along row axis\n",
    "Having learned how to append Series, you'll now learn how to achieve the same result by concatenating Series instead. You'll continue to work with the sales data you've seen previously.\n",
    "\n",
    "Your job is to use **`pd.concat()`** with a list of Series to achieve the same result that you would get by chaining calls to **`.append().`**\n",
    "\n",
    "You may be wondering about the difference between **`pd.concat()`** and pandas' **`.append()`** method. One way to think of the difference is that **`.append()`** is a specific case of a concatenation, while **`pd.concat()`** gives you more flexibility, as you'll see in later exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Date\n",
       " 2015-01-21 19:13:21    11\n",
       " 2015-01-09 05:23:51     8\n",
       " 2015-01-06 17:19:34    17\n",
       " 2015-01-02 09:51:06    16\n",
       " 2015-01-11 14:51:02    11\n",
       " 2015-01-01 07:31:20    18\n",
       " 2015-01-24 08:01:16     1\n",
       " 2015-01-25 15:40:07     6\n",
       " 2015-01-13 05:36:12     7\n",
       " 2015-01-03 18:00:19    19\n",
       " 2015-01-16 00:33:47    17\n",
       " 2015-01-16 07:21:12    13\n",
       " 2015-01-20 19:49:24    12\n",
       " 2015-01-26 01:50:25    14\n",
       " 2015-01-15 02:38:25    16\n",
       " 2015-01-06 13:47:37    16\n",
       " 2015-01-15 15:33:40     7\n",
       " 2015-01-27 07:11:55    18\n",
       " 2015-01-20 11:28:02    13\n",
       " 2015-01-16 19:20:46     8\n",
       " Name: Units, dtype: int64, Date\n",
       " 2015-02-26 08:57:45     4\n",
       " 2015-02-16 12:09:19    10\n",
       " 2015-02-03 14:14:18    13\n",
       " 2015-02-02 08:33:01     3\n",
       " 2015-02-25 00:29:00    10\n",
       " 2015-02-05 01:53:06    19\n",
       " 2015-02-09 08:57:30    19\n",
       " 2015-02-11 20:03:08     7\n",
       " 2015-02-04 21:52:45    14\n",
       " 2015-02-09 13:09:55     7\n",
       " 2015-02-07 22:58:10     1\n",
       " 2015-02-11 22:50:44     4\n",
       " 2015-02-26 08:58:51     1\n",
       " 2015-02-05 22:05:03    10\n",
       " 2015-02-04 15:36:29    13\n",
       " 2015-02-19 16:02:58    10\n",
       " 2015-02-19 10:59:33    16\n",
       " 2015-02-02 20:54:49     9\n",
       " 2015-02-21 05:01:26     3\n",
       " 2015-02-21 20:41:47     3\n",
       " Name: Units, dtype: int64, Date\n",
       " 2015-03-22 14:42:25     6\n",
       " 2015-03-12 18:33:06    19\n",
       " 2015-03-22 03:58:28     8\n",
       " 2015-03-15 00:53:12    19\n",
       " 2015-03-17 19:25:37    10\n",
       " 2015-03-16 05:54:06     3\n",
       " 2015-03-25 10:18:10     9\n",
       " 2015-03-25 16:42:42    12\n",
       " 2015-03-26 05:20:04     3\n",
       " 2015-03-06 10:11:45    17\n",
       " 2015-03-22 21:14:39    11\n",
       " 2015-03-17 19:38:12     8\n",
       " 2015-03-28 19:20:38     5\n",
       " 2015-03-13 04:41:32     8\n",
       " 2015-03-06 02:03:56    17\n",
       " 2015-03-13 11:40:16    11\n",
       " 2015-03-27 08:29:45     6\n",
       " 2015-03-21 06:42:41    19\n",
       " 2015-03-15 08:50:45    18\n",
       " 2015-03-13 16:25:24     9\n",
       " Name: Units, dtype: int64]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty list: units\n",
    "units = []\n",
    "\n",
    "# Build the list of Series\n",
    "for month in [jan, feb, mar]:\n",
    "    units.append(month.Units)\n",
    "units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2015-01-21 19:13:21    11\n",
       "2015-01-09 05:23:51     8\n",
       "2015-01-06 17:19:34    17\n",
       "2015-01-02 09:51:06    16\n",
       "2015-01-11 14:51:02    11\n",
       "2015-01-01 07:31:20    18\n",
       "2015-01-24 08:01:16     1\n",
       "2015-01-25 15:40:07     6\n",
       "2015-01-13 05:36:12     7\n",
       "2015-01-03 18:00:19    19\n",
       "2015-01-16 00:33:47    17\n",
       "2015-01-16 07:21:12    13\n",
       "2015-01-20 19:49:24    12\n",
       "2015-01-26 01:50:25    14\n",
       "2015-01-15 02:38:25    16\n",
       "2015-01-06 13:47:37    16\n",
       "2015-01-15 15:33:40     7\n",
       "2015-01-27 07:11:55    18\n",
       "2015-01-20 11:28:02    13\n",
       "2015-01-16 19:20:46     8\n",
       "2015-02-26 08:57:45     4\n",
       "2015-02-16 12:09:19    10\n",
       "2015-02-03 14:14:18    13\n",
       "2015-02-02 08:33:01     3\n",
       "2015-02-25 00:29:00    10\n",
       "2015-02-05 01:53:06    19\n",
       "2015-02-09 08:57:30    19\n",
       "2015-02-11 20:03:08     7\n",
       "2015-02-04 21:52:45    14\n",
       "2015-02-09 13:09:55     7\n",
       "2015-02-07 22:58:10     1\n",
       "2015-02-11 22:50:44     4\n",
       "2015-02-26 08:58:51     1\n",
       "2015-02-05 22:05:03    10\n",
       "2015-02-04 15:36:29    13\n",
       "2015-02-19 16:02:58    10\n",
       "2015-02-19 10:59:33    16\n",
       "2015-02-02 20:54:49     9\n",
       "2015-02-21 05:01:26     3\n",
       "2015-02-21 20:41:47     3\n",
       "2015-03-22 14:42:25     6\n",
       "2015-03-12 18:33:06    19\n",
       "2015-03-22 03:58:28     8\n",
       "2015-03-15 00:53:12    19\n",
       "2015-03-17 19:25:37    10\n",
       "2015-03-16 05:54:06     3\n",
       "2015-03-25 10:18:10     9\n",
       "2015-03-25 16:42:42    12\n",
       "2015-03-26 05:20:04     3\n",
       "2015-03-06 10:11:45    17\n",
       "2015-03-22 21:14:39    11\n",
       "2015-03-17 19:38:12     8\n",
       "2015-03-28 19:20:38     5\n",
       "2015-03-13 04:41:32     8\n",
       "2015-03-06 02:03:56    17\n",
       "2015-03-13 11:40:16    11\n",
       "2015-03-27 08:29:45     6\n",
       "2015-03-21 06:42:41    19\n",
       "2015-03-15 08:50:45    18\n",
       "2015-03-13 16:25:24     9\n",
       "Name: Units, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the list: quarter1\n",
    "quarter1 = pd.concat([jan.Units, feb.Units, mar.Units], axis='rows')\n",
    "quarter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print slices from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending DataFrames with ignore_index\n",
    "In this exercise, you'll use the Baby Names Dataset (from data.gov) again. This time, names_1981 and names_1881 are to be loaded without specifying an Index column (so the default Indexes for both are RangeIndexes).\n",
    "\n",
    "You'll use the DataFrame **`.append()`** method to make a DataFrame **`combined_names`**. To distinguish rows from the original two DataFrames, you'll add a **`'year'`** column to each with the year (1881 or 1981 in this case). In addition, you'll specify **`ignore_index=True`** so that the index values are not used along the concatenation axis. The resulting axis will instead be labeled **`0, 1, ..., n-1`**, which is useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name gender  count\n",
      "0       Mary      F   6919\n",
      "1       Anna      F   2698\n",
      "2       Emma      F   2034\n",
      "3  Elizabeth      F   1852\n",
      "4   Margaret      F   1658\n",
      "       name gender  count\n",
      "0  Jennifer      F  57032\n",
      "1   Jessica      F  42519\n",
      "2    Amanda      F  34370\n",
      "3     Sarah      F  28162\n",
      "4   Melissa      F  28003\n"
     ]
    }
   ],
   "source": [
    "# Import the data files\n",
    "names_1881 = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Baby names/names1881.csv', \n",
    "                         header=None, names=['name', 'gender', 'count'])\n",
    "names_1981 = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Baby names/names1981.csv', \n",
    "                         header=None, names=['name', 'gender', 'count'])\n",
    "print(names_1881.head())\n",
    "print(names_1981.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   name gender  count  year\n",
      "0  Mary      F   6919  1881\n",
      "1  Anna      F   2698  1881\n",
      "2  Emma      F   2034  1881\n",
      "       name gender  count  year\n",
      "0  Jennifer      F  57032  1981\n",
      "1   Jessica      F  42519  1981\n"
     ]
    }
   ],
   "source": [
    "# Add 'year' column to names_1881 and names_1981\n",
    "names_1881['year'] = 1881\n",
    "names_1981['year'] = 1981\n",
    "\n",
    "print(names_1881.head(3))\n",
    "print(names_1981.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19455, 4)\n",
      "(1935, 4)\n",
      "(21390, 4)\n"
     ]
    }
   ],
   "source": [
    "# Append names_1981 after names_1881 with ignore_index=True: combined_names\n",
    "combined_names = names_1881.append(names_1981, ignore_index=True)\n",
    "\n",
    "# Print shapes of names_1981, names_1881, and combined_names\n",
    "print(names_1981.shape)\n",
    "print(names_1881.shape)\n",
    "print(combined_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>F</td>\n",
       "      <td>1769</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14390</th>\n",
       "      <td>Morgan</td>\n",
       "      <td>M</td>\n",
       "      <td>766</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name gender  count  year\n",
       "1283   Morgan      M     23  1881\n",
       "2096   Morgan      F   1769  1981\n",
       "14390  Morgan      M    766  1981"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all rows that contain the name 'Morgan'\n",
    "combined_names.loc[combined_names.name == 'Morgan', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating pandas DataFrames along column axis\n",
    "The function **`pd.concat()`** can concatenate DataFrames horizontally as well as vertically (vertical is the default). To make the DataFrames stack horizontally, you have to specify the keyword argument **`axis=1 or axis='columns'`**.\n",
    "\n",
    "In this exercise, you'll use weather data with maximum and mean daily temperatures sampled at different rates (quarterly versus monthly). You'll concatenate the rows of both and see that, where rows are missing in the coarser DataFrame, null values are inserted in the concatenated DataFrame. This corresponds to an *outer join* (which you will explore in more detail in later exercises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weather_max and weather_mean Dataframes\n",
    "\n",
    "weather_max = pd.DataFrame({'Max TemperatureF': [68,89,91,84]}, index= ['Jan', 'Apr', 'Jul', 'Oct'] )\n",
    "weather_max.index.name = 'Month'\n",
    "weather_mean = pd.DataFrame({'Mean TemperatureF':[32.354839, 28.714286,35.0,53.1,62.612903,70.133333,72.870968,\n",
    "                                                  70.0,63.766667,55.451613,39.8,34.935484]}, \n",
    "                            index=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
    "weather_mean.index.name = 'Month'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max TemperatureF</th>\n",
       "      <th>Mean TemperatureF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apr</th>\n",
       "      <td>89.0</td>\n",
       "      <td>53.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aug</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dec</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feb</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan</th>\n",
       "      <td>68.0</td>\n",
       "      <td>32.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jul</th>\n",
       "      <td>91.0</td>\n",
       "      <td>72.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>May</th>\n",
       "      <td>NaN</td>\n",
       "      <td>62.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nov</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct</th>\n",
       "      <td>84.0</td>\n",
       "      <td>55.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep</th>\n",
       "      <td>NaN</td>\n",
       "      <td>63.766667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Max TemperatureF  Mean TemperatureF\n",
       "Apr              89.0          53.100000\n",
       "Aug               NaN          70.000000\n",
       "Dec               NaN          34.935484\n",
       "Feb               NaN          28.714286\n",
       "Jan              68.0          32.354839\n",
       "Jul              91.0          72.870968\n",
       "Jun               NaN          70.133333\n",
       "Mar               NaN          35.000000\n",
       "May               NaN          62.612903\n",
       "Nov               NaN          39.800000\n",
       "Oct              84.0          55.451613\n",
       "Sep               NaN          63.766667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate weather_max and weather_mean horizontally: weather\n",
    "weather = pd.concat([weather_max,weather_mean], axis='columns') # or axis=1\n",
    "\n",
    "# Print weather\n",
    "weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading multiple files to build a DataFrame\n",
    "It is often convenient to build a large DataFrame by parsing many files as DataFrames and concatenating them all at once. You'll do this here with three files, but, in principle, this approach can be used to combine data from dozens or hundreds of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                bronze  silver    gold\n",
      "France           475.0   461.0     NaN\n",
      "Germany          454.0     NaN   407.0\n",
      "Italy              NaN   394.0   460.0\n",
      "Soviet Union     584.0   627.0   838.0\n",
      "United Kingdom   505.0   591.0   498.0\n",
      "United States   1052.0  1195.0  2088.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Not sure why this would not work in the Jupyter Notebook, yet worked in DataCamp\n",
    "for medal in medal_types:\n",
    "\n",
    "    # Create the file name: file_name\n",
    "    file_name = \"%s_top5.csv\" % medal\n",
    "    \n",
    "    # Create list of column names: columns\n",
    "    columns = ['Country', medal]\n",
    "    \n",
    "    # Read file_name into a DataFrame: df\n",
    "    medal_df = pd.read_csv(file_name, header=0, index_col='Country', names=columns)\n",
    "\n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "\n",
    "# Concatenate medals horizontally: medals\n",
    "medals = pd.concat(medals, axis='columns')\n",
    "\n",
    "# Print medals\n",
    "print(medals)\n",
    "'''\n",
    "medal_types = ['bronze','silver','gold']\n",
    "medals = []\n",
    "for medal in medal_types:\n",
    "\n",
    "    # Create the file name: file_name\n",
    "    file_name = 'D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Summer Olympic medals/%s_top5.csv' % medal\n",
    "    \n",
    "    # Create list of column names: columns\n",
    "    columns = ['Country', medal]\n",
    "    \n",
    "    # Read file_name into a DataFrame: df\n",
    "    medal_df = pd.read_csv(file_name, header=0, index_col='Country', names=columns)\n",
    "\n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "\n",
    "# Concatenate medals horizontally: medals\n",
    "medals = pd.concat(medals, axis='columns')\n",
    "\n",
    "# Print medals\n",
    "print(medals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating vertically to get MultiIndexed rows\n",
    "When stacking a sequence of DataFrames vertically, it is sometimes desirable to construct a MultiIndex to indicate the DataFrame from which each row originated. \n",
    "\n",
    "This can be done by specifying the **`keys`** parameter in the call to **`pd.concat()`**, which generates a hierarchical index with the labels from keys as the outermost index label. So you don't have to rename the columns of each DataFrame as you load it. Instead, only the Index column needs to be specified.\n",
    "\n",
    "Here, you'll continue working with DataFrames compiled from The Guardian's Olympic medal dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Total\n",
      "       Country               \n",
      "bronze United States   1052.0\n",
      "       Soviet Union     584.0\n",
      "       United Kingdom   505.0\n",
      "       France           475.0\n",
      "       Germany          454.0\n",
      "silver United States   1195.0\n",
      "       Soviet Union     627.0\n",
      "       United Kingdom   591.0\n",
      "       France           461.0\n",
      "       Italy            394.0\n",
      "gold   United States   2088.0\n",
      "       Soviet Union     838.0\n",
      "       United Kingdom   498.0\n",
      "       Italy            460.0\n",
      "       Germany          407.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "DataCamp Code(That executed) :\n",
    "for medal in medal_types:\n",
    "\n",
    "    file_name = \"%s_top5.csv\" % medal\n",
    "    \n",
    "    # Read file_name into a DataFrame: medal_df\n",
    "    medal_df = pd.read_csv(file_name, index_col='Country')\n",
    "    \n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "    \n",
    "# Concatenate medals: medals\n",
    "medals = pd.concat(medals, keys=['bronze','silver','gold'])\n",
    "\n",
    "# Print medals in entirety\n",
    "print(medals)'''\n",
    "\n",
    "# My Code that bombed\n",
    "medal_types = ['bronze','silver','gold']\n",
    "medals = []\n",
    "for medal in medal_types:\n",
    "\n",
    "    # Create the file name: file_name\n",
    "    file_name = 'D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Summer Olympic medals/%s_top5.csv' % medal\n",
    "    \n",
    "    # Create list of column names: columns\n",
    "    columns = ['Country', medal]\n",
    "    \n",
    "    # Read file_name into a DataFrame: df\n",
    "    medal_df = pd.read_csv(file_name, index_col='Country')\n",
    "    \n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "    \n",
    "# Concatenate medals: medals\n",
    "medals = pd.concat(medals, keys=['bronze','silver','gold'])\n",
    "\n",
    "# Print medals in entirety\n",
    "print(medals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing MultiIndexed DataFrames\n",
    "This exercise picks up where the last ended (again using The Guardian's Olympic medal dataset).\n",
    "\n",
    "You are provided with the MultiIndexed DataFrame as produced at the end of the preceding exercise. Your task is to sort the DataFrame and to use the pd.IndexSlice to extract specific slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total    454.0\n",
      "Name: (bronze, Germany), dtype: float64\n",
      "                 Total\n",
      "Country               \n",
      "France           461.0\n",
      "Italy            394.0\n",
      "Soviet Union     627.0\n",
      "United Kingdom   591.0\n",
      "United States   1195.0\n",
      "                       Total\n",
      "       Country              \n",
      "bronze United Kingdom  505.0\n",
      "gold   United Kingdom  498.0\n",
      "silver United Kingdom  591.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This should work when we get the 'medals' situation figured out\n",
    "'''\n",
    "# Sort the entries of medals: medals_sorted\n",
    "medals_sorted = medals.sort_index(level=0)\n",
    "\n",
    "# Print the number of Bronze medals won by Germany\n",
    "print(medals_sorted.loc[('bronze','Germany')])\n",
    "\n",
    "# Print data about silver medals\n",
    "print(medals_sorted.loc['silver'])\n",
    "\n",
    "# Create alias for pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Print all the data on medals won by the United Kingdom\n",
    "print(medals_sorted.loc[idx[:,'United Kingdom'], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating horizontally to get MultiIndexed columns\n",
    "It is also possible to construct a DataFrame with hierarchically indexed columns. For this exercise, you'll start with pandas imported and a list of three DataFrames called **`dataframes`**. \n",
    "\n",
    "All three DataFrames contain **`'Company', 'Product', and 'Units'`** columns with a **`'Date'`** column as the index pertaining to sales transactions during the month of February, 2015. The first DataFrame describes **Hardware** transactions, the second describes **Software** transactions, and the third, **Service** transactions.\n",
    "\n",
    "Your task is to concatenate the DataFrames horizontally and to create a MultiIndex on the columns. From there, you can summarize the resulting DataFrame and slice some information from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                             Company   Product  Units\n",
       " Date                                                 \n",
       " 2015-02-04 21:52:45  Acme Coporation  Hardware     14\n",
       " 2015-02-07 22:58:10  Acme Coporation  Hardware      1\n",
       " 2015-02-19 10:59:33        Mediacore  Hardware     16\n",
       " 2015-02-02 20:54:49        Mediacore  Hardware      9\n",
       " 2015-02-21 20:41:47            Hooli  Hardware      3,\n",
       "                              Company   Product  Units\n",
       " Date                                                 \n",
       " 2015-02-16 12:09:19            Hooli  Software     10\n",
       " 2015-02-03 14:14:18          Initech  Software     13\n",
       " 2015-02-02 08:33:01            Hooli  Software      3\n",
       " 2015-02-05 01:53:06  Acme Coporation  Software     19\n",
       " 2015-02-11 20:03:08          Initech  Software      7\n",
       " 2015-02-09 13:09:55        Mediacore  Software      7\n",
       " 2015-02-11 22:50:44            Hooli  Software      4\n",
       " 2015-02-04 15:36:29        Streeplex  Software     13\n",
       " 2015-02-21 05:01:26        Mediacore  Software      3,\n",
       "                        Company  Product  Units\n",
       " Date                                          \n",
       " 2015-02-26 08:57:45  Streeplex  Service      4\n",
       " 2015-02-25 00:29:00    Initech  Service     10\n",
       " 2015-02-09 08:57:30  Streeplex  Service     19\n",
       " 2015-02-26 08:58:51  Streeplex  Service      1\n",
       " 2015-02-05 22:05:03      Hooli  Service     10\n",
       " 2015-02-19 16:02:58  Mediacore  Service     10]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the list of file names: filenames\n",
    "filenames = ['D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Sales/feb-sales-Hardware.csv',\n",
    "             'D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Sales/feb-sales-Software.csv',\n",
    "             'D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Sales/feb-sales-Service.csv']\n",
    "# Create the list of three DataFrames: dataframes\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename, index_col='Date', parse_dates=True))\n",
    "    \n",
    "dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Hardware</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Software</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Service</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units</th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units</th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-02 08:33:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hooli</td>\n",
       "      <td>Software</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-02 20:54:49</th>\n",
       "      <td>Mediacore</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03 14:14:18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Initech</td>\n",
       "      <td>Software</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 15:36:29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Streeplex</td>\n",
       "      <td>Software</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 21:52:45</th>\n",
       "      <td>Acme Coporation</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Hardware                   Software            \\\n",
       "                             Company   Product Units    Company   Product   \n",
       "Date                                                                        \n",
       "2015-02-02 08:33:01              NaN       NaN   NaN      Hooli  Software   \n",
       "2015-02-02 20:54:49        Mediacore  Hardware   9.0        NaN       NaN   \n",
       "2015-02-03 14:14:18              NaN       NaN   NaN    Initech  Software   \n",
       "2015-02-04 15:36:29              NaN       NaN   NaN  Streeplex  Software   \n",
       "2015-02-04 21:52:45  Acme Coporation  Hardware  14.0        NaN       NaN   \n",
       "\n",
       "                          Service                \n",
       "                    Units Company Product Units  \n",
       "Date                                             \n",
       "2015-02-02 08:33:01   3.0     NaN     NaN   NaN  \n",
       "2015-02-02 20:54:49   NaN     NaN     NaN   NaN  \n",
       "2015-02-03 14:14:18  13.0     NaN     NaN   NaN  \n",
       "2015-02-04 15:36:29  13.0     NaN     NaN   NaN  \n",
       "2015-02-04 21:52:45   NaN     NaN     NaN   NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate dataframes: february\n",
    "february = pd.concat(dataframes, axis=1, keys=['Hardware','Software','Service'])\n",
    "february.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2015-02-02 08:33:01 to 2015-02-26 08:58:51\n",
      "Data columns (total 9 columns):\n",
      "(Hardware, Company)    5 non-null object\n",
      "(Hardware, Product)    5 non-null object\n",
      "(Hardware, Units)      5 non-null float64\n",
      "(Software, Company)    9 non-null object\n",
      "(Software, Product)    9 non-null object\n",
      "(Software, Units)      9 non-null float64\n",
      "(Service, Company)     6 non-null object\n",
      "(Service, Product)     6 non-null object\n",
      "(Service, Units)       6 non-null float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "february.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Hardware</th>\n",
       "      <th>Software</th>\n",
       "      <th>Service</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Company</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-02 08:33:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hooli</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-02 20:54:49</th>\n",
       "      <td>Mediacore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03 14:14:18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Initech</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 15:36:29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Streeplex</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 21:52:45</th>\n",
       "      <td>Acme Coporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-05 01:53:06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Acme Coporation</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-05 22:05:03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hooli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-07 22:58:10</th>\n",
       "      <td>Acme Coporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Hardware         Software Service\n",
       "                             Company          Company Company\n",
       "Date                                                         \n",
       "2015-02-02 08:33:01              NaN            Hooli     NaN\n",
       "2015-02-02 20:54:49        Mediacore              NaN     NaN\n",
       "2015-02-03 14:14:18              NaN          Initech     NaN\n",
       "2015-02-04 15:36:29              NaN        Streeplex     NaN\n",
       "2015-02-04 21:52:45  Acme Coporation              NaN     NaN\n",
       "2015-02-05 01:53:06              NaN  Acme Coporation     NaN\n",
       "2015-02-05 22:05:03              NaN              NaN   Hooli\n",
       "2015-02-07 22:58:10  Acme Coporation              NaN     NaN"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Create the slice: slice_2_8\n",
    "slice_2_8 = february.loc['2015-02-02':'2015-02-08', idx[:, 'Company']]\n",
    "\n",
    "# Print slice_2_8\n",
    "slice_2_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating DataFrames from a dict\n",
    "You're now going to revisit the sales data you worked with earlier in the chapter. Three DataFrames **`jan, feb, and mar`** have been pre-loaded for you. Your task is to aggregate the sum of all sales over the **`'Company'`** column into a single DataFrame. You'll do this by constructing a dictionary of these DataFrames and then concatenating them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Company   Product  Units\n",
      "Date                                           \n",
      "2015-01-21 19:13:21  Streeplex  Hardware     11\n",
      "2015-01-09 05:23:51  Streeplex   Service      8\n",
      "2015-01-06 17:19:34    Initech  Hardware     17\n",
      "2015-01-02 09:51:06      Hooli  Hardware     16\n",
      "2015-01-11 14:51:02      Hooli  Hardware     11\n",
      "                       Company   Product  Units\n",
      "Date                                           \n",
      "2015-02-26 08:57:45  Streeplex   Service      4\n",
      "2015-02-16 12:09:19      Hooli  Software     10\n",
      "2015-02-03 14:14:18    Initech  Software     13\n",
      "2015-02-02 08:33:01      Hooli  Software      3\n",
      "2015-02-25 00:29:00    Initech   Service     10\n",
      "                       Company   Product  Units\n",
      "Date                                           \n",
      "2015-03-22 14:42:25  Mediacore  Software      6\n",
      "2015-03-12 18:33:06    Initech   Service     19\n",
      "2015-03-22 03:58:28  Streeplex  Software      8\n",
      "2015-03-15 00:53:12      Hooli  Hardware     19\n",
      "2015-03-17 19:25:37      Hooli  Hardware     10\n"
     ]
    }
   ],
   "source": [
    "print(jan.head())\n",
    "print(feb.head())\n",
    "print(mar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('january',                              Company   Product  Units\n",
       "  Date                                                 \n",
       "  2015-01-21 19:13:21        Streeplex  Hardware     11\n",
       "  2015-01-09 05:23:51        Streeplex   Service      8\n",
       "  2015-01-06 17:19:34          Initech  Hardware     17\n",
       "  2015-01-02 09:51:06            Hooli  Hardware     16\n",
       "  2015-01-11 14:51:02            Hooli  Hardware     11\n",
       "  2015-01-01 07:31:20  Acme Coporation  Software     18\n",
       "  2015-01-24 08:01:16          Initech  Software      1\n",
       "  2015-01-25 15:40:07          Initech   Service      6\n",
       "  2015-01-13 05:36:12            Hooli   Service      7\n",
       "  2015-01-03 18:00:19            Hooli   Service     19\n",
       "  2015-01-16 00:33:47            Hooli  Hardware     17\n",
       "  2015-01-16 07:21:12          Initech   Service     13\n",
       "  2015-01-20 19:49:24  Acme Coporation  Hardware     12\n",
       "  2015-01-26 01:50:25  Acme Coporation  Software     14\n",
       "  2015-01-15 02:38:25  Acme Coporation   Service     16\n",
       "  2015-01-06 13:47:37  Acme Coporation  Software     16\n",
       "  2015-01-15 15:33:40        Mediacore  Hardware      7\n",
       "  2015-01-27 07:11:55        Streeplex   Service     18\n",
       "  2015-01-20 11:28:02        Streeplex  Software     13\n",
       "  2015-01-16 19:20:46        Mediacore   Service      8),\n",
       " ('february',                              Company   Product  Units\n",
       "  Date                                                 \n",
       "  2015-02-26 08:57:45        Streeplex   Service      4\n",
       "  2015-02-16 12:09:19            Hooli  Software     10\n",
       "  2015-02-03 14:14:18          Initech  Software     13\n",
       "  2015-02-02 08:33:01            Hooli  Software      3\n",
       "  2015-02-25 00:29:00          Initech   Service     10\n",
       "  2015-02-05 01:53:06  Acme Coporation  Software     19\n",
       "  2015-02-09 08:57:30        Streeplex   Service     19\n",
       "  2015-02-11 20:03:08          Initech  Software      7\n",
       "  2015-02-04 21:52:45  Acme Coporation  Hardware     14\n",
       "  2015-02-09 13:09:55        Mediacore  Software      7\n",
       "  2015-02-07 22:58:10  Acme Coporation  Hardware      1\n",
       "  2015-02-11 22:50:44            Hooli  Software      4\n",
       "  2015-02-26 08:58:51        Streeplex   Service      1\n",
       "  2015-02-05 22:05:03            Hooli   Service     10\n",
       "  2015-02-04 15:36:29        Streeplex  Software     13\n",
       "  2015-02-19 16:02:58        Mediacore   Service     10\n",
       "  2015-02-19 10:59:33        Mediacore  Hardware     16\n",
       "  2015-02-02 20:54:49        Mediacore  Hardware      9\n",
       "  2015-02-21 05:01:26        Mediacore  Software      3\n",
       "  2015-02-21 20:41:47            Hooli  Hardware      3),\n",
       " ('march',                              Company   Product  Units\n",
       "  Date                                                 \n",
       "  2015-03-22 14:42:25        Mediacore  Software      6\n",
       "  2015-03-12 18:33:06          Initech   Service     19\n",
       "  2015-03-22 03:58:28        Streeplex  Software      8\n",
       "  2015-03-15 00:53:12            Hooli  Hardware     19\n",
       "  2015-03-17 19:25:37            Hooli  Hardware     10\n",
       "  2015-03-16 05:54:06        Mediacore  Software      3\n",
       "  2015-03-25 10:18:10          Initech  Hardware      9\n",
       "  2015-03-25 16:42:42        Streeplex  Hardware     12\n",
       "  2015-03-26 05:20:04        Streeplex  Software      3\n",
       "  2015-03-06 10:11:45        Mediacore  Software     17\n",
       "  2015-03-22 21:14:39          Initech  Hardware     11\n",
       "  2015-03-17 19:38:12            Hooli  Hardware      8\n",
       "  2015-03-28 19:20:38  Acme Coporation   Service      5\n",
       "  2015-03-13 04:41:32        Streeplex  Hardware      8\n",
       "  2015-03-06 02:03:56        Mediacore  Software     17\n",
       "  2015-03-13 11:40:16          Initech  Software     11\n",
       "  2015-03-27 08:29:45        Mediacore  Software      6\n",
       "  2015-03-21 06:42:41        Mediacore  Hardware     19\n",
       "  2015-03-15 08:50:45          Initech  Hardware     18\n",
       "  2015-03-13 16:25:24        Streeplex  Software      9)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the list of tuples: month_list\n",
    "month_list = [('january', jan),('february', feb), ('march', mar)]\n",
    "month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">february</th>\n",
       "      <th>Acme Coporation</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hooli</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Initech</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mediacore</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streeplex</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">january</th>\n",
       "      <th>Acme Coporation</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hooli</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Initech</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mediacore</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streeplex</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">march</th>\n",
       "      <th>Acme Coporation</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hooli</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Initech</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mediacore</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Streeplex</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Units\n",
       "         Company               \n",
       "february Acme Coporation     34\n",
       "         Hooli               30\n",
       "         Initech             30\n",
       "         Mediacore           45\n",
       "         Streeplex           37\n",
       "january  Acme Coporation     76\n",
       "         Hooli               70\n",
       "         Initech             37\n",
       "         Mediacore           15\n",
       "         Streeplex           50\n",
       "march    Acme Coporation      5\n",
       "         Hooli               37\n",
       "         Initech             68\n",
       "         Mediacore           68\n",
       "         Streeplex           40"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty dictionary: month_dict\n",
    "month_dict = {}\n",
    "\n",
    "for month_name, month_data in month_list:\n",
    "\n",
    "    # Group month_data: month_dict[month_name]\n",
    "    month_dict[month_name] = month_data.groupby('Company').sum()\n",
    "\n",
    "# Concatenate data in month_dict: sales\n",
    "sales = pd.concat(month_dict)\n",
    "\n",
    "# Print sales\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>february</th>\n",
       "      <th>Mediacore</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>january</th>\n",
       "      <th>Mediacore</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>march</th>\n",
       "      <th>Mediacore</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Units\n",
       "         Company         \n",
       "february Mediacore     45\n",
       "january  Mediacore     15\n",
       "march    Mediacore     68"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all sales by Mediacore\n",
    "idx = pd.IndexSlice\n",
    "sales.loc[idx[:, 'Mediacore'], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating DataFrames with inner join\n",
    "Here, you'll continue working with DataFrames compiled from **The Guardian's Olympic medal dataset.**\n",
    "\n",
    "The DataFrames **`bronze, silver, and gold`** have been pre-loaded for you.\n",
    "\n",
    "Your task is to compute an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "bronze = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Summer Olympic medals/bronze_top5.csv', index_col='Country')\n",
    "silver = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Summer Olympic medals/silver_top5.csv', index_col='Country')\n",
    "gold = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/Summer Olympic medals/gold_top5.csv', index_col='Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>bronze</th>\n",
       "      <th>silver</th>\n",
       "      <th>gold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>1052.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>2088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soviet Union</th>\n",
       "      <td>584.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>838.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>505.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bronze  silver    gold\n",
       "                 Total   Total   Total\n",
       "Country                               \n",
       "United States   1052.0  1195.0  2088.0\n",
       "Soviet Union     584.0   627.0   838.0\n",
       "United Kingdom   505.0   591.0   498.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the list of DataFrames: medal_list\n",
    "medal_list = [bronze, silver, gold]\n",
    "\n",
    "# Concatenate medal_list horizontally using an inner join: medals\n",
    "medals = pd.concat(medal_list, axis=1, join='inner', keys=['bronze','silver','gold'])\n",
    "\n",
    "# Print medals\n",
    "medals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling & concatenating DataFrames with inner join\n",
    "In this exercise, you'll compare the historical 10-year GDP (Gross Domestic Product) growth in the US and in China. The data for the US starts in 1947 and is recorded quarterly; by contrast, the data for China starts in 1961 and is recorded annually.\n",
    "\n",
    "You'll need to use a combination of resampling and an inner join to align the index labels. You'll need an appropriate offset alias for resampling, and the method **`.resample()`** must be chained with some kind of aggregation method (**`.pct_change()`** and **`.last()`** in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "us = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/GDP/gdp_usa.csv', \n",
    "                 index_col='Year', parse_dates=True, header=0, names=['Year', 'US'])\n",
    "china = pd.read_csv('D:/Springboard_DataCamp/data/Merging_DataFrames_with_Pandas/GDP/gdp_china.csv', \n",
    "                    index_col='Year', parse_dates=True, header=0, names=['Year', 'China'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                China\n",
      "Year                 \n",
      "1960-01-01  59.184116\n",
      "1961-01-01  49.557050\n",
      "1962-01-01  46.685179\n",
      "1963-01-01  50.097303\n",
      "1964-01-01  59.062255\n",
      "               US\n",
      "Year             \n",
      "1947-01-01  243.1\n",
      "1947-04-01  246.3\n",
      "1947-07-01  250.1\n",
      "1947-10-01  260.3\n",
      "1948-01-01  266.2\n"
     ]
    }
   ],
   "source": [
    "print(china.head())\n",
    "print(us.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
