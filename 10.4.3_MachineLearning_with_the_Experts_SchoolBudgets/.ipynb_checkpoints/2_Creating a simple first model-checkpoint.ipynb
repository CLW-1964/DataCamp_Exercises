{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>Object_Description</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>SALARIES OF REGULAR EMPLOYEES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERSONNEL-PAID LEAVE</td>\n",
       "      <td>-0.024490</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRAFTS, TRADES, AND SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STAFF SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251131</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Special Education</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>SALARIES OF REGULAR EMPLOYEES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022645</td>\n",
       "      <td>SPECIAL ED. - MILD/MODERATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>-1279.639890</td>\n",
       "      <td>SPECIAL EDUCATION-HD HIGH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECIAL EDUCATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169065</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School on Central Budgets</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>PreK</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>SALARIES OF PART TIME EMPLOYEE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARLY CHILDHOOD EDUCATION</td>\n",
       "      <td>-0.020676</td>\n",
       "      <td>TUITION BASED - ECE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-OTHER</td>\n",
       "      <td>-966.621829</td>\n",
       "      <td>SUPPORT SERVICES-INSTRUCTIONAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSTRUCTIONAL STAFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111271</th>\n",
       "      <td>Special Population Program Management &amp; Support</td>\n",
       "      <td>ISPD</td>\n",
       "      <td>Leadership &amp; Management</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>ELL</td>\n",
       "      <td>Other</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>SALARIES OF PART TIME EMPLOYEE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENGLISH FOR SPEAKERS OF OTHER</td>\n",
       "      <td>-0.020012</td>\n",
       "      <td>ELA S - TEACHING SPANISH ONLY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OFFICE/ADMINISTRATIVE SUPPORT</td>\n",
       "      <td>-595.654318</td>\n",
       "      <td>SUPPORT SERVICES-INSTRUCTIONAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSTRUCTIONAL STAFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29425</th>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>SALARIES OF REGULAR EMPLOYEES</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018115</td>\n",
       "      <td>ALL DAY KINDERGARTEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>-869.659820</td>\n",
       "      <td>GENERAL ELEMENTARY EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Function          Use  \\\n",
       "11890                                          NO_LABEL     NO_LABEL   \n",
       "251131                             Teacher Compensation  Instruction   \n",
       "169065                             Teacher Compensation  Instruction   \n",
       "111271  Special Population Program Management & Support         ISPD   \n",
       "29425                              Teacher Compensation  Instruction   \n",
       "\n",
       "                          Sharing   Reporting       Student_Type  \\\n",
       "11890                    NO_LABEL    NO_LABEL           NO_LABEL   \n",
       "251131            School Reported      School  Special Education   \n",
       "169065  School on Central Budgets  Non-School               PreK   \n",
       "111271    Leadership & Management  Non-School                ELL   \n",
       "29425             School Reported      School        Unspecified   \n",
       "\n",
       "       Position_Type               Object_Type     Pre_K   Operating_Status  \\\n",
       "11890       NO_LABEL                  NO_LABEL  NO_LABEL      Non-Operating   \n",
       "251131       Teacher  Base Salary/Compensation  NO_LABEL  PreK-12 Operating   \n",
       "169065       Teacher  Base Salary/Compensation      PreK  PreK-12 Operating   \n",
       "111271         Other  Base Salary/Compensation  NO_LABEL  PreK-12 Operating   \n",
       "29425        Teacher  Base Salary/Compensation  NO_LABEL  PreK-12 Operating   \n",
       "\n",
       "                    Object_Description         ...           \\\n",
       "11890    SALARIES OF REGULAR EMPLOYEES         ...            \n",
       "251131   SALARIES OF REGULAR EMPLOYEES         ...            \n",
       "169065  SALARIES OF PART TIME EMPLOYEE         ...            \n",
       "111271  SALARIES OF PART TIME EMPLOYEE         ...            \n",
       "29425    SALARIES OF REGULAR EMPLOYEES         ...            \n",
       "\n",
       "       Sub_Object_Description           Location_Description       FTE  \\\n",
       "11890                     NaN           PERSONNEL-PAID LEAVE -0.024490   \n",
       "251131                    NaN                            NaN -0.022645   \n",
       "169065                    NaN      EARLY CHILDHOOD EDUCATION -0.020676   \n",
       "111271                    NaN  ENGLISH FOR SPEAKERS OF OTHER -0.020012   \n",
       "29425                     NaN                            NaN -0.018115   \n",
       "\n",
       "                 Function_Description Facility_or_Department  \\\n",
       "11890                     NON-PROJECT                    NaN   \n",
       "251131    SPECIAL ED. - MILD/MODERATE                    NaN   \n",
       "169065            TUITION BASED - ECE                    NaN   \n",
       "111271  ELA S - TEACHING SPANISH ONLY                    NaN   \n",
       "29425            ALL DAY KINDERGARTEN                    NaN   \n",
       "\n",
       "                       Position_Extra        Total  \\\n",
       "11890    CRAFTS, TRADES, AND SERVICES          NaN   \n",
       "251131     PROFESSIONAL-INSTRUCTIONAL -1279.639890   \n",
       "169065             PROFESSIONAL-OTHER  -966.621829   \n",
       "111271  OFFICE/ADMINISTRATIVE SUPPORT  -595.654318   \n",
       "29425      PROFESSIONAL-INSTRUCTIONAL  -869.659820   \n",
       "\n",
       "                   Program_Description Fund_Description               Text_1  \n",
       "11890                   STAFF SERVICES              NaN              CENTRAL  \n",
       "251131       SPECIAL EDUCATION-HD HIGH              NaN    SPECIAL EDUCATION  \n",
       "169065  SUPPORT SERVICES-INSTRUCTIONAL              NaN  INSTRUCTIONAL STAFF  \n",
       "111271  SUPPORT SERVICES-INSTRUCTIONAL              NaN  INSTRUCTIONAL STAFF  \n",
       "29425     GENERAL ELEMENTARY EDUCATION              NaN  REGULAR INSTRUCTION  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the first dataset\n",
    "file = 'D:/Springboard_DataCamp/data/MachineLearning_with_the_Experts_SchoolBudgets/TrainingData_v1.csv'\n",
    "df = pd.read_csv(file, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a train-test split in scikit-learn\n",
    "The first step is to split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least min_count examples of each label appear in each split:**` multilabel_train_test_split`**.\n",
    "\n",
    "See the full code for multilabel_train_test_split below.\n",
    "\n",
    "You'll start with a simple model that uses just the numeric columns of your DataFrame when calling multilabel_train_test_split. The data has been read into a DataFrame df and a list consisting of just the numeric columns is available as NUMERIC_COLUMNS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NUMERIC_COLUMNS and LABELS lists\n",
    "NUMERIC_COLUMNS = ['FTE', 'Total']\n",
    "LABELS = ['Function', 'Use', 'Sharing', 'Reporting', 'Student_Type', 'Position_Type', 'Object_Type', 'Pre_K', 'Operating_Status']\n",
    "\n",
    "\n",
    "#code for multilabel_train_test_split\n",
    "from warnings import warn\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).any():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320049 entries, 11890 to 415831\n",
      "Data columns (total 2 columns):\n",
      "FTE      320049 non-null float64\n",
      "Total    320049 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80012 entries, 46366 to 343458\n",
      "Data columns (total 2 columns):\n",
      "FTE      80012 non-null float64\n",
      "Total    80012 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320049 entries, 11890 to 415831\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80012 entries, 46366 to 343458\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "With split data in hand, you're only a few lines away from training a model.\n",
    "\n",
    "In this exercise, you will import the logistic regression and one versus rest classifiers in order to fit a multi-class logistic regression model to the **`NUMERIC_COLUMNS`** of your feature data.\n",
    "\n",
    "Then you'll test and print the accuracy with the **`.score()`** method to see the results of training.\n",
    "\n",
    "*Before you train! Remember, we're ultimately going to be using logloss to score our model*, so don't worry too much about the accuracy here. Keep in mind that you're throwing away all of the text data in the dataset - that's by far most of the data! So don't get your hopes up for a killer performance just yet. We're just interested in getting things up and running at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Create the DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf =  OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your model to predict values on holdout data\n",
    "You're ready to make some predictions! Remember, the train-test-split you've carried out so far is for model development. The original competition provides an additional test set, for which you'll never actually see the correct labels. This is called the \"holdout data.\"\n",
    "\n",
    "The point of the holdout data is to provide a fair test for machine learning competitions. If the labels aren't known by anyone but DataCamp, DrivenData, or whoever is hosting the competition, you can be sure that no one submits a mere copy of labels to artificially pump up the performance on their model.\n",
    "\n",
    "Remember that the original goal is to predict the **probability of each label**. In this exercise you'll do just that by using the **`.predict_proba()`** method on your trained model.\n",
    "\n",
    "First, however, you'll need to load the holdout data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit it to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Load the holdout data: holdout\n",
    "holdout = pd.read_csv('D:/Springboard_DataCamp/data/MachineLearning_with_the_Experts_SchoolBudgets/HoldoutData.csv', index_col=0)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing out your results to a csv for submission\n",
    "At last, you're ready to submit some predictions for scoring. In this exercise, you'll write your predictions to a .csv using the .to_csv() method on a pandas DataFrame. Then you'll evaluate your performance according to the LogLoss metric discussed earlier!\n",
    "\n",
    "You'll need to make sure your submission obeys the correct format.\n",
    "\n",
    "To do this, you'll use your predictions values to create a new DataFrame, prediction_df.\n",
    "\n",
    "Interpreting LogLoss & Beating the Benchmark:\n",
    "\n",
    "When interpreting your log loss score, keep in mind that the score will change based on the number of samples tested. To get a sense of how this very basic model performs, compare your score to the DrivenData benchmark model performance: 2.0455, which merely submitted uniform probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e5df4767a3ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Submit the predictions for scoring: score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_submission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'D:/Springboard_DataCamp/data/MachineLearning_with_the_Experts_SchoolBudgets/predictions.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Print score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'score_submission' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS]).columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('D:/Springboard_DataCamp/data/MachineLearning_with_the_Experts_SchoolBudgets/predictions.csv')\n",
    "\n",
    "# Submit the predictions for scoring: score\n",
    "score = score_submission(pred_path='D:/Springboard_DataCamp/data/MachineLearning_with_the_Experts_SchoolBudgets/predictions.csv')\n",
    "\n",
    "# Print score\n",
    "print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a bag-of-words in scikit-learn\n",
    "In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.\n",
    "\n",
    "You will focus on one feature only, the **`Position_Extra`** column, which describes any additional information not captured by the Position_Type label.\n",
    "\n",
    "For example, in the Shell you can check out the budget item in row 8960 of the data using **`df.loc[8960]`**. Looking at the output reveals that this **`Object_Description`** is overtime pay. For who? The **`Position Type`** is merely \"other\", but the **`Position Extra`** elaborates: \"BUS DRIVER\". Explore the column further to see more instances. It has a lot of NaN values.\n",
    "\n",
    "Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.\n",
    "\n",
    "For comparison purposes, the first 15 tokens of vec_basic, which splits df.Position_Extra into tokens when it encounters only whitespace characters, have been printed along with the length of the representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Function                                         Student Transportation\n",
       "Use                                                                 O&M\n",
       "Sharing                                                 Shared Services\n",
       "Reporting                                                    Non-School\n",
       "Student_Type                                                Unspecified\n",
       "Position_Type                                                     Other\n",
       "Object_Type                                  Other Compensation/Stipend\n",
       "Pre_K                                                          Non PreK\n",
       "Operating_Status                                      PreK-12 Operating\n",
       "Object_Description        Extra Duty Pay/Overtime For Support Personnel\n",
       "Text_2                                                              NaN\n",
       "SubFund_Description                                          Operations\n",
       "Job_Title_Description                     TRANSPORTATION,BUS DR., RADIO\n",
       "Text_3                                                              NaN\n",
       "Text_4                                     transportation - Second Runs\n",
       "Sub_Object_Description    Extra Duty Pay/Overtime For Support Personnel\n",
       "Location_Description                                        Unallocated\n",
       "FTE                                                                 NaN\n",
       "Function_Description                                     Transportation\n",
       "Facility_or_Department                        Transportation Department\n",
       "Position_Extra                                               BUS DRIVER\n",
       "Total                                                           1752.45\n",
       "Program_Description                                       Undistributed\n",
       "Fund_Description                                 General Operating Fund\n",
       "Text_1                                                    EXTENDED DAYS\n",
       "Name: 8960, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[8960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 385 tokens in Position_Extra if we split on non-alpha numeric. The first 15 tokens are:\n",
      "['1st', '2nd', '3rd', '4th', '56', '5th', '9th', 'a', 'ab', 'accountability', 'adaptive', 'addit', 'additional', 'adm', 'admin']\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('', inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern= TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric. The first 15 tokens are:\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining text columns for tokenization\n",
    "In order to get a bag-of-words representation for all of the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string.\n",
    "\n",
    "In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. **`CountVectorizer`** expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string.\n",
    "\n",
    "In this exercise, you'll complete the function definition **`combine_text_columns()`**. When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the **`.fit_transform()`** method.\n",
    "\n",
    "Note that the function uses NUMERIC_COLUMNS and LABELS to determine which columns to drop. These lists have been loaded into the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in a token?\n",
    "Now you will use **`combine_text_columns`** to convert all training text data in your DataFrame to a single vector that can be passed to the vectorizer object and made into a bag-of-words using the **`.fit_transform()`** method.\n",
    "\n",
    "You'll compare the effect of tokenizing using any non-whitespace characters as a token and using only alphanumeric characters as a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4737 tokens in the dataset\n",
      "There are 3279 alpha-numeric tokens in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Import the CountVectorizer\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern= TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern= TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
