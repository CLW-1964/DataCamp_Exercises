{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras libraries\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a model\n",
    "Now you'll get to work with your first model in Keras, and will immediately be able to run more complex neural network models on larger datasets compared to the first two chapters.\n",
    "\n",
    "To start, you'll take the skeleton of a neural network and add a hidden layer and an output layer. You'll then fit that model and see Keras do the optimization so your model continually gets better.\n",
    "\n",
    "As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience. You can find the dataset in a pandas dataframe called df. For convenience, everything in df except for the target has been converted to a NumPy matrix called predictors. The target, wage_per_hour, is available as a NumPy matrix called target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the first dataset\n",
    "file = 'D:/Springboard_DataCamp/data/Deep_Learning_in_Python/hourly_wages.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.1 ,  4.95,  6.67,  4.  ,  7.5 , 13.07,  4.45, 19.47, 13.28,\n",
       "        8.75])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.array(df['wage_per_hour'])\n",
    "target[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8, 21, ...,  0,  1,  0],\n",
       "       [ 0,  9, 42, ...,  0,  1,  0],\n",
       "       [ 0, 12,  1, ...,  0,  1,  0],\n",
       "       ...,\n",
       "       [ 1, 17, 25, ...,  0,  0,  0],\n",
       "       [ 1, 12, 13, ...,  1,  0,  0],\n",
       "       [ 0, 16, 33, ...,  0,  1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = np.array(df.iloc[:,1:])\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8, 21, ...,  0,  1,  0],\n",
       "       [ 0,  9, 42, ...,  0,  1,  0],\n",
       "       [ 0, 12,  1, ...,  0,  1,  0],\n",
       "       ...,\n",
       "       [ 1, 17, 25, ...,  0,  0,  0],\n",
       "       [ 1, 12, 13, ...,  1,  0,  0],\n",
       "       [ 0, 16, 33, ...,  0,  1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative method for getting predictors into a matrix\n",
    "predictors = df.drop(['wage_per_hour'], axis=1).as_matrix()\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "You're now going to compile the model you specified earlier. To compile the model, you need to specify the optimizer and loss function to use. In this exercise, you'll use the Adam optimizer and the mean squared error loss function. Go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "You're at the most fun part. You'll now fit the model. Recall that the data to be used as predictive features is loaded in a NumPy matrix called **`predictors`** and the data to be predicted is stored in a NumPy matrix called **`target`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "534/534 [==============================] - 1s 1ms/step - loss: 40.3891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cacf7955f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last steps in classification models\n",
    "You'll now create a classification model using the titanic dataset, which has been pre-loaded into a DataFrame called df. You'll take information about the passengers and predict which ones survived.\n",
    "\n",
    "The predictive variables are stored in a NumPy array **`predictors`**. The target to predict is in **`df.survived`**, though you'll have to manipulate it for keras. The number of predictive features is stored in **`n_cols`**.\n",
    "\n",
    "Here, you'll use the **`'sgd'`** optimizer, which stands for Stochastic Gradient Descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1                0   \n",
       "1         1       1  38.0      1      0  71.2833     0                0   \n",
       "2         1       3  26.0      0      0   7.9250     0                0   \n",
       "3         1       1  35.0      1      0  53.1000     0                0   \n",
       "4         0       3  35.0      0      0   8.0500     1                0   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the first dataset\n",
    "file = 'D:/Springboard_DataCamp/data/Deep_Learning_in_Python/titanic_all_numeric.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        , 22.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.        , 38.        ,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 3.        , 26.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 3.        , 29.69911765,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.        , 26.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 3.        , 32.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = np.array(df.iloc[:, 1:])\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = predictors.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 403us/step - loss: 2.4823 - acc: 0.5544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cacfbe5748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "The trained network from your previous coding exercise is now stored as **`model`**. New data to make predictions is stored in a NumPy array as **`pred_data`**. Use model to make predictions on your new data.\n",
    "\n",
    "In this exercise, your predictions will be probabilities, which is the most common way for data scientists to communicate their predictions to colleagues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.array([[2, 34.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 26.25, 0, False, 0, 0, 1],\n",
    "       [1, 11.0, 1, 2, 120.0, 1, False, 0, 0, 1],\n",
    "       [3, 0.42, 0, 1, 8.5167, 1, False, 1, 0, 0],\n",
    "       [3, 27.0, 0, 0, 6.975, 1, False, 0, 0, 1],\n",
    "       [3, 31.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 7.775, 0, False, 0, 0, 1],\n",
    "       [2, 39.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 33.0, 1, 0, 53.1, 0, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8875, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 0, 24.15, 1, False, 0, 0, 1],\n",
    "       [2, 35.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 6.0, 4, 2, 31.275, 0, False, 0, 0, 1],\n",
    "       [3, 30.5, 0, 0, 8.05, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 0.0, 1, True, 0, 0, 1],\n",
    "       [3, 23.0, 0, 0, 7.925, 0, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 43.0, 0, 0, 6.45, 1, False, 0, 0, 1],\n",
    "       [3, 10.0, 3, 2, 27.9, 1, False, 0, 0, 1],\n",
    "       [1, 52.0, 1, 1, 93.5, 0, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [1, 38.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 1, 12.475, 0, False, 0, 0, 1],\n",
    "       [3, 2.0, 4, 1, 39.6875, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 6.95, 1, True, 0, 1, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 56.4958, 1, True, 0, 0, 1],\n",
    "       [2, 1.0, 0, 2, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.75, 1, True, 0, 1, 0],\n",
    "       [1, 62.0, 0, 0, 80.0, 0, False, 0, 0, 0],\n",
    "       [3, 15.0, 1, 0, 14.4542, 0, False, 1, 0, 0],\n",
    "       [2, 0.83, 1, 1, 18.75, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 23.0, 0, 0, 7.8542, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 8.3, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 1, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [3, 21.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 8.05, 1, True, 0, 0, 1],\n",
    "       [3, 32.0, 0, 0, 56.4958, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 29.7, 1, True, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 7.925, 1, False, 0, 0, 1],\n",
    "       [2, 16.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [1, 30.0, 0, 0, 31.0, 0, False, 1, 0, 0],\n",
    "       [3, 34.5, 0, 0, 6.4375, 1, False, 1, 0, 0],\n",
    "       [3, 17.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 42.0, 0, 0, 7.55, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 1, True, 0, 0, 1],\n",
    "       [3, 35.0, 0, 0, 7.8958, 1, False, 1, 0, 0],\n",
    "       [2, 28.0, 0, 1, 33.0, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 1, 0, 89.1042, 0, True, 1, 0, 0],\n",
    "       [3, 4.0, 4, 2, 31.275, 1, False, 0, 0, 1],\n",
    "       [3, 74.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [3, 9.0, 1, 1, 15.2458, 0, False, 1, 0, 0],\n",
    "       [1, 16.0, 0, 1, 39.4, 0, False, 0, 0, 1],\n",
    "       [2, 44.0, 1, 0, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 1, 9.35, 0, False, 0, 0, 1],\n",
    "       [1, 45.0, 1, 1, 164.8667, 0, False, 0, 0, 1],\n",
    "       [1, 51.0, 0, 0, 26.55, 1, False, 0, 0, 1],\n",
    "       [3, 24.0, 0, 3, 19.2583, 0, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 41.0, 2, 0, 14.1083, 1, False, 0, 0, 1],\n",
    "       [2, 21.0, 1, 0, 11.5, 1, False, 0, 0, 1],\n",
    "       [1, 48.0, 0, 0, 25.9292, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 0, True, 0, 0, 1],\n",
    "       [2, 24.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 42.0, 0, 0, 13.0, 0, False, 0, 0, 1],\n",
    "       [2, 27.0, 1, 0, 13.8583, 0, False, 1, 0, 0],\n",
    "       [1, 31.0, 0, 0, 50.4958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 9.5, 1, True, 0, 0, 1],\n",
    "       [3, 4.0, 1, 1, 11.1333, 1, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [1, 47.0, 1, 1, 52.5542, 0, False, 0, 0, 1],\n",
    "       [1, 33.0, 0, 0, 5.0, 1, False, 0, 0, 1],\n",
    "       [3, 47.0, 0, 0, 9.0, 1, False, 0, 0, 1],\n",
    "       [2, 28.0, 1, 0, 24.0, 0, False, 1, 0, 0],\n",
    "       [3, 15.0, 0, 0, 7.225, 0, False, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 9.8458, 1, False, 0, 0, 1],\n",
    "       [3, 19.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.8958, 1, True, 0, 0, 1],\n",
    "       [1, 56.0, 0, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [2, 25.0, 0, 1, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 33.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 22.0, 0, 0, 10.5167, 0, False, 0, 0, 1],\n",
    "       [2, 28.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 25.0, 0, 0, 7.05, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 5, 29.125, 0, False, 0, 1, 0],\n",
    "       [2, 27.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 19.0, 0, 0, 30.0, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 1, 2, 23.45, 0, True, 0, 0, 1],\n",
    "       [1, 26.0, 0, 0, 30.0, 1, False, 1, 0, 0],\n",
    "       [3, 32.0, 0, 0, 7.75, 1, False, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.        ,  34.        ,   0.        ,   0.        ,\n",
       "         13.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  31.        ,   1.        ,   1.        ,\n",
       "         26.25      ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  11.        ,   1.        ,   2.        ,\n",
       "        120.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   0.42      ,   0.        ,   1.        ,\n",
       "          8.5167    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  27.        ,   0.        ,   0.        ,\n",
       "          6.975     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  31.        ,   0.        ,   0.        ,\n",
       "          7.775     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  39.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  18.        ,   0.        ,   0.        ,\n",
       "          7.775     ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  39.        ,   0.        ,   0.        ,\n",
       "         13.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  33.        ,   1.        ,   0.        ,\n",
       "         53.1       ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  26.        ,   0.        ,   0.        ,\n",
       "          7.8875    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  39.        ,   0.        ,   0.        ,\n",
       "         24.15      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  35.        ,   0.        ,   0.        ,\n",
       "         10.5       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   6.        ,   4.        ,   2.        ,\n",
       "         31.275     ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  30.5       ,   0.        ,   0.        ,\n",
       "          8.05      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  23.        ,   0.        ,   0.        ,\n",
       "          7.925     ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  31.        ,   1.        ,   1.        ,\n",
       "         37.0042    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  43.        ,   0.        ,   0.        ,\n",
       "          6.45      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  10.        ,   3.        ,   2.        ,\n",
       "         27.9       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  52.        ,   1.        ,   1.        ,\n",
       "         93.5       ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  27.        ,   0.        ,   0.        ,\n",
       "          8.6625    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  38.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  27.        ,   0.        ,   1.        ,\n",
       "         12.475     ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   2.        ,   4.        ,   1.        ,\n",
       "         39.6875    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          6.95      ,   1.        ,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "         56.4958    ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,   1.        ,   0.        ,   2.        ,\n",
       "         37.0042    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          7.75      ,   1.        ,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  1.        ,  62.        ,   0.        ,   0.        ,\n",
       "         80.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  15.        ,   1.        ,   0.        ,\n",
       "         14.4542    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  2.        ,   0.83      ,   1.        ,   1.        ,\n",
       "         18.75      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          7.2292    ,   1.        ,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  23.        ,   0.        ,   0.        ,\n",
       "          7.8542    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  18.        ,   0.        ,   0.        ,\n",
       "          8.3       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  39.        ,   1.        ,   1.        ,\n",
       "         83.1583    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  21.        ,   0.        ,   0.        ,\n",
       "          8.6625    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          8.05      ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  32.        ,   0.        ,   0.        ,\n",
       "         56.4958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  29.69911765,   0.        ,   0.        ,\n",
       "         29.7       ,   1.        ,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  20.        ,   0.        ,   0.        ,\n",
       "          7.925     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  16.        ,   0.        ,   0.        ,\n",
       "         10.5       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  30.        ,   0.        ,   0.        ,\n",
       "         31.        ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  34.5       ,   0.        ,   0.        ,\n",
       "          6.4375    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  17.        ,   0.        ,   0.        ,\n",
       "          8.6625    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  42.        ,   0.        ,   0.        ,\n",
       "          7.55      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   8.        ,   2.        ,\n",
       "         69.55      ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  35.        ,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  2.        ,  28.        ,   0.        ,   1.        ,\n",
       "         33.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  29.69911765,   1.        ,   0.        ,\n",
       "         89.1042    ,   0.        ,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,   4.        ,   4.        ,   2.        ,\n",
       "         31.275     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  74.        ,   0.        ,   0.        ,\n",
       "          7.775     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   9.        ,   1.        ,   1.        ,\n",
       "         15.2458    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  1.        ,  16.        ,   0.        ,   1.        ,\n",
       "         39.4       ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  44.        ,   1.        ,   0.        ,\n",
       "         26.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  18.        ,   0.        ,   1.        ,\n",
       "          9.35      ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  45.        ,   1.        ,   1.        ,\n",
       "        164.8667    ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  51.        ,   0.        ,   0.        ,\n",
       "         26.55      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  24.        ,   0.        ,   3.        ,\n",
       "         19.2583    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          7.2292    ,   1.        ,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  41.        ,   2.        ,   0.        ,\n",
       "         14.1083    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  21.        ,   1.        ,   0.        ,\n",
       "         11.5       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  48.        ,   0.        ,   0.        ,\n",
       "         25.9292    ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   8.        ,   2.        ,\n",
       "         69.55      ,   0.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  24.        ,   0.        ,   0.        ,\n",
       "         13.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  42.        ,   0.        ,   0.        ,\n",
       "         13.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  27.        ,   1.        ,   0.        ,\n",
       "         13.8583    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  1.        ,  31.        ,   0.        ,   0.        ,\n",
       "         50.4958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          9.5       ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   4.        ,   1.        ,   1.        ,\n",
       "         11.1333    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  26.        ,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  47.        ,   1.        ,   1.        ,\n",
       "         52.5542    ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  33.        ,   0.        ,   0.        ,\n",
       "          5.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  47.        ,   0.        ,   0.        ,\n",
       "          9.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  28.        ,   1.        ,   0.        ,\n",
       "         24.        ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  15.        ,   0.        ,   0.        ,\n",
       "          7.225     ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  20.        ,   0.        ,   0.        ,\n",
       "          9.8458    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  19.        ,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  56.        ,   0.        ,   1.        ,\n",
       "         83.1583    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  2.        ,  25.        ,   0.        ,   1.        ,\n",
       "         26.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  33.        ,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  22.        ,   0.        ,   0.        ,\n",
       "         10.5167    ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  28.        ,   0.        ,   0.        ,\n",
       "         10.5       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  25.        ,   0.        ,   0.        ,\n",
       "          7.05      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  39.        ,   0.        ,   5.        ,\n",
       "         29.125     ,   0.        ,   0.        ,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  2.        ,  27.        ,   0.        ,   0.        ,\n",
       "         13.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  19.        ,   0.        ,   0.        ,\n",
       "         30.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   1.        ,   2.        ,\n",
       "         23.45      ,   0.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  26.        ,   0.        ,   0.        ,\n",
       "         30.        ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  32.        ,   0.        ,   0.        ,\n",
       "          7.75      ,   1.        ,   0.        ,   0.        ,\n",
       "          1.        ,   0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 440us/step - loss: 1.9817 - acc: 0.5746\n",
      "[0.07318906 0.08182028 0.99869823 0.5392729  0.11240233 0.08762219\n",
      " 0.05888123 0.1835526  0.05311545 0.7575298  0.11905245 0.04380081\n",
      " 0.06928095 0.49345043 0.09031092 0.10410164 0.13567446 0.24144319\n",
      " 0.0407422  0.42180106 0.94494945 0.11177637 0.0627891  0.08414725\n",
      " 0.72699183 0.10612077 0.87087405 0.8566818  0.10549156 0.40054268\n",
      " 0.29151133 0.5449283  0.1088649  0.14060797 0.16445635 0.95732266\n",
      " 0.14536792 0.09345157 0.8451867  0.21045494 0.1559849  0.18019518\n",
      " 0.21930566 0.08175469 0.16746591 0.04333079 0.639746   0.07882816\n",
      " 0.18064323 0.98831487 0.49777177 0.00504516 0.5277146  0.75179577\n",
      " 0.0334115  0.14482196 0.9997485  0.02256621 0.10186089 0.1088649\n",
      " 0.02804454 0.12057403 0.03091611 0.66227704 0.1139039  0.04134399\n",
      " 0.12263686 0.7499313  0.09299476 0.39596945 0.11904921 0.08978014\n",
      " 0.08230046 0.03100823 0.15886177 0.26306173 0.14241642 0.16180506\n",
      " 0.09350023 0.7613893  0.15898885 0.07725275 0.13810314 0.10612904\n",
      " 0.12676041 0.02206235 0.09724814 0.60513395 0.06496026 0.30753165\n",
      " 0.09237675]\n"
     ]
    }
   ],
   "source": [
    "# Specify, compile, and fit the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(predictors, target)\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:, 1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing optimization parameters\n",
    "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.\n",
    "\n",
    "For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function get_new_model() that creates an unoptimized model to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (n_cols,)\n",
    "def get_new_model(input_shape = input_shape):\n",
    " model = Sequential()\n",
    " model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    " model.add(Dense(100, activation='relu'))\n",
    " model.add(Dense(2, activation='softmax'))\n",
    " return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 528us/step - loss: 3.1996\n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 558us/step - loss: 1.8382\n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/1\n",
      "891/891 [==============================] - 1s 628us/step - loss: 6.3360\n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer = my_optimizer, loss = 'categorical_crossentropy')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model accuracy on validation dataset\n",
    "Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as **`model`**. Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/1\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 1.1589 - acc: 0.6164 - val_loss: 0.5934 - val_acc: 0.7127\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping: Optimizing the optimization\n",
    "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for **`epochs`** in your call to **`.fit()`**, as Dan showed in the video.\n",
    "\n",
    "The model you'll optimize has been specified as model. As before, the data is pre-loaded as predictors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 1.1344 - acc: 0.5682 - val_loss: 0.5988 - val_acc: 0.7164\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.6771 - acc: 0.6533 - val_loss: 0.5810 - val_acc: 0.7164\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.6379 - acc: 0.6902 - val_loss: 0.5078 - val_acc: 0.7537\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.6162 - acc: 0.6790 - val_loss: 0.5068 - val_acc: 0.7575\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.5629 - acc: 0.7223 - val_loss: 0.5511 - val_acc: 0.7425\n",
      "Epoch 6/30\n",
      "623/623 [==============================] - 0s 101us/step - loss: 0.5777 - acc: 0.7319 - val_loss: 0.6184 - val_acc: 0.6493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cad41c7dd8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because optimization will automatically stop when it is no longer helpful, it is okay to specify the maximum number of epochs as 30 rather than using the default of 10 that you've used so far. Here, it seems like the optimization stopped after 6 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with wider networks\n",
    "\n",
    "A model called **`model_1`** has been pre-loaded. This is a relatively small network, with only 10 units in each hidden layer.\n",
    "\n",
    "In this exercise you'll create a new model called **`model_2`** which is similar to **`model_1`**, except it has 100 units in each hidden layer.\n",
    "\n",
    "After you create **`model_2`**, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument **`verbose=False`** in the fitting commands to print out fewer updates, since you will look at these graphically instead of as text.\n",
    "\n",
    "Because you are fitting two models, it will take a moment to see the outputs after you hit run, so be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# create model_1\n",
    "# Specify the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(10, activation='relu', input_shape = input_shape))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_1\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue model is model_2, the red is model_1. model_2 had a lower loss value, so it is the better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding layers to a network\n",
    "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers).\n",
    "\n",
    "Once again, you have a baseline model called **`model_1`** as a starting point. It has 1 hidden layer, with 50 units. You will create a similar network with 3 hidden layers (still keeping 50 units in each layer).\n",
    "\n",
    "This will again take a moment to fit both models, so you'll need to wait a few seconds to see the results after you run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# create model_1\n",
    "model_1.add(Dense(50, activation='relu', input_shape = input_shape))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "# Compile model_1\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu', input_shape = input_shape))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue model is model_2, the red is model_1. model_1 had a lower loss value, so it is the better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
