{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras libraries\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying a model\n",
    "Now you'll get to work with your first model in Keras, and will immediately be able to run more complex neural network models on larger datasets compared to the first two chapters.\n",
    "\n",
    "To start, you'll take the skeleton of a neural network and add a hidden layer and an output layer. You'll then fit that model and see Keras do the optimization so your model continually gets better.\n",
    "\n",
    "As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience. You can find the dataset in a pandas dataframe called df. For convenience, everything in df except for the target has been converted to a NumPy matrix called predictors. The target, wage_per_hour, is available as a NumPy matrix called target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.95</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.50</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
       "0           5.10      0              8              21   35       1     1   \n",
       "1           4.95      0              9              42   57       1     1   \n",
       "2           6.67      0             12               1   19       0     0   \n",
       "3           4.00      0             12               4   22       0     0   \n",
       "4           7.50      0             12              17   35       0     1   \n",
       "\n",
       "   south  manufacturing  construction  \n",
       "0      0              1             0  \n",
       "1      0              1             0  \n",
       "2      0              1             0  \n",
       "3      0              0             0  \n",
       "4      0              0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the first dataset\n",
    "file = 'D:/Springboard_DataCamp/data/Deep_Learning_in_Python/hourly_wages.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.1 ,  4.95,  6.67,  4.  ,  7.5 , 13.07,  4.45, 19.47, 13.28,\n",
       "        8.75])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.array(df['wage_per_hour'])\n",
    "target[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8, 21, ...,  0,  1,  0],\n",
       "       [ 0,  9, 42, ...,  0,  1,  0],\n",
       "       [ 0, 12,  1, ...,  0,  1,  0],\n",
       "       ...,\n",
       "       [ 1, 17, 25, ...,  0,  0,  0],\n",
       "       [ 1, 12, 13, ...,  1,  0,  0],\n",
       "       [ 0, 16, 33, ...,  0,  1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = np.array(df.iloc[:,1:])\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8, 21, ...,  0,  1,  0],\n",
       "       [ 0,  9, 42, ...,  0,  1,  0],\n",
       "       [ 0, 12,  1, ...,  0,  1,  0],\n",
       "       ...,\n",
       "       [ 1, 17, 25, ...,  0,  0,  0],\n",
       "       [ 1, 12, 13, ...,  1,  0,  0],\n",
       "       [ 0, 16, 33, ...,  0,  1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative method for getting predictors into a matrix\n",
    "predictors = df.drop(['wage_per_hour'], axis=1).as_matrix()\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "You're now going to compile the model you specified earlier. To compile the model, you need to specify the optimizer and loss function to use. In this exercise, you'll use the Adam optimizer and the mean squared error loss function. Go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "You're at the most fun part. You'll now fit the model. Recall that the data to be used as predictive features is loaded in a NumPy matrix called **`predictors`** and the data to be predicted is stored in a NumPy matrix called **`target`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sixsi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "534/534 [==============================] - 0s 933us/step - loss: 84.6231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293f9759fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the model\n",
    "n_cols = predictors.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last steps in classification models\n",
    "You'll now create a classification model using the titanic dataset, which has been pre-loaded into a DataFrame called df. You'll take information about the passengers and predict which ones survived.\n",
    "\n",
    "The predictive variables are stored in a NumPy array **`predictors`**. The target to predict is in **`df.survived`**, though you'll have to manipulate it for keras. The number of predictive features is stored in **`n_cols`**.\n",
    "\n",
    "Here, you'll use the **`'sgd'`** optimizer, which stands for Stochastic Gradient Descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1                0   \n",
       "1         1       1  38.0      1      0  71.2833     0                0   \n",
       "2         1       3  26.0      0      0   7.9250     0                0   \n",
       "3         1       1  35.0      1      0  53.1000     0                0   \n",
       "4         0       3  35.0      0      0   8.0500     1                0   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the first dataset\n",
    "file = 'D:/Springboard_DataCamp/data/Deep_Learning_in_Python/titanic_all_numeric.csv'\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.        , 22.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.        , 38.        ,  1.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 3.        , 26.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 3.        , 29.69911765,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.        , 26.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 3.        , 32.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = np.array(df.iloc[:, 1:])\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols = predictors.shape[1]\n",
    "n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 395us/step - loss: 2.6989 - acc: 0.5993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293facbcc88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "The trained network from your previous coding exercise is now stored as **`model`**. New data to make predictions is stored in a NumPy array as **`pred_data`**. Use model to make predictions on your new data.\n",
    "\n",
    "In this exercise, your predictions will be probabilities, which is the most common way for data scientists to communicate their predictions to colleagues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = np.array([[2, 34.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 26.25, 0, False, 0, 0, 1],\n",
    "       [1, 11.0, 1, 2, 120.0, 1, False, 0, 0, 1],\n",
    "       [3, 0.42, 0, 1, 8.5167, 1, False, 1, 0, 0],\n",
    "       [3, 27.0, 0, 0, 6.975, 1, False, 0, 0, 1],\n",
    "       [3, 31.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 7.775, 0, False, 0, 0, 1],\n",
    "       [2, 39.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 33.0, 1, 0, 53.1, 0, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8875, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 0, 24.15, 1, False, 0, 0, 1],\n",
    "       [2, 35.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 6.0, 4, 2, 31.275, 0, False, 0, 0, 1],\n",
    "       [3, 30.5, 0, 0, 8.05, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 0.0, 1, True, 0, 0, 1],\n",
    "       [3, 23.0, 0, 0, 7.925, 0, False, 0, 0, 1],\n",
    "       [2, 31.0, 1, 1, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 43.0, 0, 0, 6.45, 1, False, 0, 0, 1],\n",
    "       [3, 10.0, 3, 2, 27.9, 1, False, 0, 0, 1],\n",
    "       [1, 52.0, 1, 1, 93.5, 0, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [1, 38.0, 0, 0, 0.0, 1, False, 0, 0, 1],\n",
    "       [3, 27.0, 0, 1, 12.475, 0, False, 0, 0, 1],\n",
    "       [3, 2.0, 4, 1, 39.6875, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 6.95, 1, True, 0, 1, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 56.4958, 1, True, 0, 0, 1],\n",
    "       [2, 1.0, 0, 2, 37.0042, 1, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.75, 1, True, 0, 1, 0],\n",
    "       [1, 62.0, 0, 0, 80.0, 0, False, 0, 0, 0],\n",
    "       [3, 15.0, 1, 0, 14.4542, 0, False, 1, 0, 0],\n",
    "       [2, 0.83, 1, 1, 18.75, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 23.0, 0, 0, 7.8542, 1, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 0, 8.3, 1, False, 0, 0, 1],\n",
    "       [1, 39.0, 1, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [3, 21.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 8.05, 1, True, 0, 0, 1],\n",
    "       [3, 32.0, 0, 0, 56.4958, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 0, 0, 29.7, 1, True, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 7.925, 1, False, 0, 0, 1],\n",
    "       [2, 16.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [1, 30.0, 0, 0, 31.0, 0, False, 1, 0, 0],\n",
    "       [3, 34.5, 0, 0, 6.4375, 1, False, 1, 0, 0],\n",
    "       [3, 17.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\n",
    "       [3, 42.0, 0, 0, 7.55, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 1, True, 0, 0, 1],\n",
    "       [3, 35.0, 0, 0, 7.8958, 1, False, 1, 0, 0],\n",
    "       [2, 28.0, 0, 1, 33.0, 1, False, 0, 0, 1],\n",
    "       [1, 29.69911764705882, 1, 0, 89.1042, 0, True, 1, 0, 0],\n",
    "       [3, 4.0, 4, 2, 31.275, 1, False, 0, 0, 1],\n",
    "       [3, 74.0, 0, 0, 7.775, 1, False, 0, 0, 1],\n",
    "       [3, 9.0, 1, 1, 15.2458, 0, False, 1, 0, 0],\n",
    "       [1, 16.0, 0, 1, 39.4, 0, False, 0, 0, 1],\n",
    "       [2, 44.0, 1, 0, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 18.0, 0, 1, 9.35, 0, False, 0, 0, 1],\n",
    "       [1, 45.0, 1, 1, 164.8667, 0, False, 0, 0, 1],\n",
    "       [1, 51.0, 0, 0, 26.55, 1, False, 0, 0, 1],\n",
    "       [3, 24.0, 0, 3, 19.2583, 0, False, 1, 0, 0],\n",
    "       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\n",
    "       [3, 41.0, 2, 0, 14.1083, 1, False, 0, 0, 1],\n",
    "       [2, 21.0, 1, 0, 11.5, 1, False, 0, 0, 1],\n",
    "       [1, 48.0, 0, 0, 25.9292, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 8, 2, 69.55, 0, True, 0, 0, 1],\n",
    "       [2, 24.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [2, 42.0, 0, 0, 13.0, 0, False, 0, 0, 1],\n",
    "       [2, 27.0, 1, 0, 13.8583, 0, False, 1, 0, 0],\n",
    "       [1, 31.0, 0, 0, 50.4958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 9.5, 1, True, 0, 0, 1],\n",
    "       [3, 4.0, 1, 1, 11.1333, 1, False, 0, 0, 1],\n",
    "       [3, 26.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [1, 47.0, 1, 1, 52.5542, 0, False, 0, 0, 1],\n",
    "       [1, 33.0, 0, 0, 5.0, 1, False, 0, 0, 1],\n",
    "       [3, 47.0, 0, 0, 9.0, 1, False, 0, 0, 1],\n",
    "       [2, 28.0, 1, 0, 24.0, 0, False, 1, 0, 0],\n",
    "       [3, 15.0, 0, 0, 7.225, 0, False, 1, 0, 0],\n",
    "       [3, 20.0, 0, 0, 9.8458, 1, False, 0, 0, 1],\n",
    "       [3, 19.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 0, 0, 7.8958, 1, True, 0, 0, 1],\n",
    "       [1, 56.0, 0, 1, 83.1583, 0, False, 1, 0, 0],\n",
    "       [2, 25.0, 0, 1, 26.0, 0, False, 0, 0, 1],\n",
    "       [3, 33.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\n",
    "       [3, 22.0, 0, 0, 10.5167, 0, False, 0, 0, 1],\n",
    "       [2, 28.0, 0, 0, 10.5, 1, False, 0, 0, 1],\n",
    "       [3, 25.0, 0, 0, 7.05, 1, False, 0, 0, 1],\n",
    "       [3, 39.0, 0, 5, 29.125, 0, False, 0, 1, 0],\n",
    "       [2, 27.0, 0, 0, 13.0, 1, False, 0, 0, 1],\n",
    "       [1, 19.0, 0, 0, 30.0, 0, False, 0, 0, 1],\n",
    "       [3, 29.69911764705882, 1, 2, 23.45, 0, True, 0, 0, 1],\n",
    "       [1, 26.0, 0, 0, 30.0, 1, False, 1, 0, 0],\n",
    "       [3, 32.0, 0, 0, 7.75, 1, False, 0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.        ,  34.        ,   0.        ,   0.        ,\n",
       "         13.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  31.        ,   1.        ,   1.        ,\n",
       "         26.25      ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  11.        ,   1.        ,   2.        ,\n",
       "        120.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   0.42      ,   0.        ,   1.        ,\n",
       "          8.5167    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  27.        ,   0.        ,   0.        ,\n",
       "          6.975     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  31.        ,   0.        ,   0.        ,\n",
       "          7.775     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  39.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  18.        ,   0.        ,   0.        ,\n",
       "          7.775     ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  39.        ,   0.        ,   0.        ,\n",
       "         13.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  33.        ,   1.        ,   0.        ,\n",
       "         53.1       ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  26.        ,   0.        ,   0.        ,\n",
       "          7.8875    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  39.        ,   0.        ,   0.        ,\n",
       "         24.15      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  35.        ,   0.        ,   0.        ,\n",
       "         10.5       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   6.        ,   4.        ,   2.        ,\n",
       "         31.275     ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  30.5       ,   0.        ,   0.        ,\n",
       "          8.05      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  23.        ,   0.        ,   0.        ,\n",
       "          7.925     ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  31.        ,   1.        ,   1.        ,\n",
       "         37.0042    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  43.        ,   0.        ,   0.        ,\n",
       "          6.45      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  10.        ,   3.        ,   2.        ,\n",
       "         27.9       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  52.        ,   1.        ,   1.        ,\n",
       "         93.5       ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  27.        ,   0.        ,   0.        ,\n",
       "          8.6625    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  38.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  27.        ,   0.        ,   1.        ,\n",
       "         12.475     ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   2.        ,   4.        ,   1.        ,\n",
       "         39.6875    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          6.95      ,   1.        ,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "         56.4958    ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,   1.        ,   0.        ,   2.        ,\n",
       "         37.0042    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          7.75      ,   1.        ,   1.        ,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  1.        ,  62.        ,   0.        ,   0.        ,\n",
       "         80.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  15.        ,   1.        ,   0.        ,\n",
       "         14.4542    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  2.        ,   0.83      ,   1.        ,   1.        ,\n",
       "         18.75      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          7.2292    ,   1.        ,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  23.        ,   0.        ,   0.        ,\n",
       "          7.8542    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  18.        ,   0.        ,   0.        ,\n",
       "          8.3       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  39.        ,   1.        ,   1.        ,\n",
       "         83.1583    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  21.        ,   0.        ,   0.        ,\n",
       "          8.6625    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          8.05      ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  32.        ,   0.        ,   0.        ,\n",
       "         56.4958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  29.69911765,   0.        ,   0.        ,\n",
       "         29.7       ,   1.        ,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  20.        ,   0.        ,   0.        ,\n",
       "          7.925     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  16.        ,   0.        ,   0.        ,\n",
       "         10.5       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  30.        ,   0.        ,   0.        ,\n",
       "         31.        ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  34.5       ,   0.        ,   0.        ,\n",
       "          6.4375    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  17.        ,   0.        ,   0.        ,\n",
       "          8.6625    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  42.        ,   0.        ,   0.        ,\n",
       "          7.55      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   8.        ,   2.        ,\n",
       "         69.55      ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  35.        ,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  2.        ,  28.        ,   0.        ,   1.        ,\n",
       "         33.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  29.69911765,   1.        ,   0.        ,\n",
       "         89.1042    ,   0.        ,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,   4.        ,   4.        ,   2.        ,\n",
       "         31.275     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  74.        ,   0.        ,   0.        ,\n",
       "          7.775     ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   9.        ,   1.        ,   1.        ,\n",
       "         15.2458    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  1.        ,  16.        ,   0.        ,   1.        ,\n",
       "         39.4       ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  44.        ,   1.        ,   0.        ,\n",
       "         26.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  18.        ,   0.        ,   1.        ,\n",
       "          9.35      ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  45.        ,   1.        ,   1.        ,\n",
       "        164.8667    ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  51.        ,   0.        ,   0.        ,\n",
       "         26.55      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  24.        ,   0.        ,   3.        ,\n",
       "         19.2583    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          7.2292    ,   1.        ,   1.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  41.        ,   2.        ,   0.        ,\n",
       "         14.1083    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  21.        ,   1.        ,   0.        ,\n",
       "         11.5       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  48.        ,   0.        ,   0.        ,\n",
       "         25.9292    ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   8.        ,   2.        ,\n",
       "         69.55      ,   0.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  24.        ,   0.        ,   0.        ,\n",
       "         13.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  42.        ,   0.        ,   0.        ,\n",
       "         13.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  27.        ,   1.        ,   0.        ,\n",
       "         13.8583    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  1.        ,  31.        ,   0.        ,   0.        ,\n",
       "         50.4958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          9.5       ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,   4.        ,   1.        ,   1.        ,\n",
       "         11.1333    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  26.        ,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  47.        ,   1.        ,   1.        ,\n",
       "         52.5542    ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  33.        ,   0.        ,   0.        ,\n",
       "          5.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  47.        ,   0.        ,   0.        ,\n",
       "          9.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  28.        ,   1.        ,   0.        ,\n",
       "         24.        ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  15.        ,   0.        ,   0.        ,\n",
       "          7.225     ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  20.        ,   0.        ,   0.        ,\n",
       "          9.8458    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  19.        ,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  56.        ,   0.        ,   1.        ,\n",
       "         83.1583    ,   0.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  2.        ,  25.        ,   0.        ,   1.        ,\n",
       "         26.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  33.        ,   0.        ,   0.        ,\n",
       "          7.8958    ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  22.        ,   0.        ,   0.        ,\n",
       "         10.5167    ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  2.        ,  28.        ,   0.        ,   0.        ,\n",
       "         10.5       ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  25.        ,   0.        ,   0.        ,\n",
       "          7.05      ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  39.        ,   0.        ,   5.        ,\n",
       "         29.125     ,   0.        ,   0.        ,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [  2.        ,  27.        ,   0.        ,   0.        ,\n",
       "         13.        ,   1.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  19.        ,   0.        ,   0.        ,\n",
       "         30.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  3.        ,  29.69911765,   1.        ,   2.        ,\n",
       "         23.45      ,   0.        ,   1.        ,   0.        ,\n",
       "          0.        ,   1.        ],\n",
       "       [  1.        ,  26.        ,   0.        ,   0.        ,\n",
       "         30.        ,   1.        ,   0.        ,   1.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  3.        ,  32.        ,   0.        ,   0.        ,\n",
       "          7.75      ,   1.        ,   0.        ,   0.        ,\n",
       "          1.        ,   0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "891/891 [==============================] - 0s 507us/step - loss: 3.1810 - acc: 0.5410\n",
      "[3.35329864e-03 1.23953195e-02 1.13043779e-06 8.90354961e-02\n",
      " 8.97290744e-03 4.88095265e-03 1.70917273e-03 3.23859341e-02\n",
      " 1.56089664e-03 6.99978089e-03 1.02999313e-02 1.43946032e-03\n",
      " 2.92952568e-03 1.55830495e-02 5.24297077e-03 1.01216128e-02\n",
      " 1.54791093e-02 6.19996665e-03 7.45909521e-04 3.02903801e-02\n",
      " 2.30341509e-04 8.78627412e-03 2.00160081e-03 8.24377406e-03\n",
      " 2.10158597e-03 8.53614230e-03 2.75140302e-03 5.52245462e-03\n",
      " 8.54147971e-03 1.01073441e-04 5.46233542e-02 4.19804044e-02\n",
      " 8.58684909e-03 1.61009636e-02 3.34210731e-02 6.47345791e-04\n",
      " 2.14292984e-02 8.33559688e-03 2.37018382e-03 1.34590222e-02\n",
      " 2.50544120e-02 5.15366718e-02 1.28108487e-02 2.94524804e-03\n",
      " 3.84792238e-02 8.74431804e-04 1.65583915e-03 2.72494229e-03\n",
      " 7.27503002e-03 4.75909008e-04 8.97934195e-03 5.53585232e-06\n",
      " 9.03654173e-02 2.52890103e-02 1.19499862e-03 3.24790850e-02\n",
      " 3.41583871e-07 3.16102261e-04 1.54529857e-02 8.58684909e-03\n",
      " 2.30876892e-03 3.56330425e-02 4.93280008e-04 2.26531248e-03\n",
      " 1.49627980e-02 9.47254768e-04 1.42972283e-02 7.13115884e-03\n",
      " 8.34504701e-03 1.03803746e-01 1.02988677e-02 1.11215003e-03\n",
      " 4.42208629e-03 3.97041644e-04 1.64008625e-02 5.21577969e-02\n",
      " 2.44714916e-02 2.90225130e-02 8.33458733e-03 2.45673815e-04\n",
      " 1.66959558e-02 3.60972248e-03 1.73868798e-02 8.50440096e-03\n",
      " 1.20805316e-02 2.80187908e-03 9.57181863e-03 4.53988202e-02\n",
      " 1.66319329e-02 1.46025792e-02 4.34767781e-03]\n"
     ]
    }
   ],
   "source": [
    "# Specify, compile, and fit the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(predictors, target)\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:, 1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing optimization parameters\n",
    "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.\n",
    "\n",
    "For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function get_new_model() that creates an unoptimized model to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-33e82095aac1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mget_new_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m  \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "def get_new_model(input_shape = input_shape):\n",
    " model = Sequential()\n",
    " model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    " model.add(Dense(100, activation='relu'))\n",
    " model.add(Dense(2, activation='softmax'))\n",
    " return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_new_model() missing 1 required positional argument: 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-864546ad5848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Build new model to test, unaffected by previous models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_new_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Create SGD optimizer with specified learning rate: my_optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_new_model() missing 1 required positional argument: 'input_shape'"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer = my_optimizer, loss = 'categorical_crossentropy')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model accuracy on validation dataset\n",
    "Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as **`model`**. Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/1\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 1.2287 - acc: 0.5827 - val_loss: 0.6401 - val_acc: 0.7164\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early stopping: Optimizing the optimization\n",
    "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for **`epochs`** in your call to **`.fit()`**, as Dan showed in the video.\n",
    "\n",
    "The model you'll optimize has been specified as model. As before, the data is pre-loaded as predictors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 1s 1ms/step - loss: 0.9253 - acc: 0.6100 - val_loss: 0.6014 - val_acc: 0.6679\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.6559 - acc: 0.6629 - val_loss: 0.5744 - val_acc: 0.7276\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.6446 - acc: 0.6774 - val_loss: 0.5389 - val_acc: 0.7463\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.6567 - acc: 0.6693 - val_loss: 0.5370 - val_acc: 0.7425\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.5969 - acc: 0.6774 - val_loss: 0.8014 - val_acc: 0.6493\n",
      "Epoch 6/30\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.6080 - acc: 0.7063 - val_loss: 0.4783 - val_acc: 0.7575\n",
      "Epoch 7/30\n",
      "623/623 [==============================] - 0s 107us/step - loss: 0.6906 - acc: 0.6517 - val_loss: 0.4851 - val_acc: 0.7724\n",
      "Epoch 8/30\n",
      "623/623 [==============================] - 0s 98us/step - loss: 0.5846 - acc: 0.6982 - val_loss: 0.4834 - val_acc: 0.7761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293fc960cf8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because optimization will automatically stop when it is no longer helpful, it is okay to specify the maximum number of epochs as 30 rather than using the default of 10 that you've used so far. Here, it seems like the optimization stopped after 7 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with wider networks\n",
    "\n",
    "A model called **`model_1`** has been pre-loaded. You can see a summary of this model printed in the IPython Shell. This is a relatively small network, with only 10 units in each hidden layer.\n",
    "\n",
    "In this exercise you'll create a new model called **`model_2`** which is similar to **`model_1`**, except it has 100 units in each hidden layer.\n",
    "\n",
    "After you create **`model_2`**, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument **`verbose=False`** in the fitting commands to print out fewer updates, since you will look at these graphically instead of as text.\n",
    "\n",
    "Because you are fitting two models, it will take a moment to see the outputs after you hit run, so be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# create model_1\n",
    "# Specify the model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(10, activation='relu', input_shape = input_shape))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_1\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue model is model_2, the red is model_1. model_2 had a lower loss value, so it is the better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding layers to a network\n",
    "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers).\n",
    "\n",
    "Once again, you have a baseline model called **`model_1`** as a starting point. It has 1 hidden layer, with 50 units. You will create a similar network with 3 hidden layers (still keeping 50 units in each layer).\n",
    "\n",
    "This will again take a moment to fit both models, so you'll need to wait a few seconds to see the results after you run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# create model_1\n",
    "model_1.add(Dense(50, activation='relu', input_shape = input_shape))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "# Compile model_1\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu', input_shape = input_shape))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue model is model_2, the red is model_1. model_1 had a lower loss value, so it is the better model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
